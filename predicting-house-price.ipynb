{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home. https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-02-19T21:33:07.284263Z","iopub.execute_input":"2023-02-19T21:33:07.284636Z","iopub.status.idle":"2023-02-19T21:33:08.154361Z","shell.execute_reply.started":"2023-02-19T21:33:07.284600Z","shell.execute_reply":"2023-02-19T21:33:08.153600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOAD DATA**","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\ndf_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nids = df_test['Id'].values","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:33:55.079259Z","iopub.execute_input":"2023-02-19T21:33:55.079959Z","iopub.status.idle":"2023-02-19T21:33:55.161119Z","shell.execute_reply.started":"2023-02-19T21:33:55.079901Z","shell.execute_reply":"2023-02-19T21:33:55.160329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2023-02-15T23:56:43.006824Z","iopub.execute_input":"2023-02-15T23:56:43.007157Z","iopub.status.idle":"2023-02-15T23:56:43.054664Z","shell.execute_reply.started":"2023-02-15T23:56:43.007128Z","shell.execute_reply":"2023-02-15T23:56:43.053783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building hypotheses. Target variable","metadata":{}},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-15T23:57:27.095763Z","iopub.execute_input":"2023-02-15T23:57:27.096092Z","iopub.status.idle":"2023-02-15T23:57:27.181275Z","shell.execute_reply.started":"2023-02-15T23:57:27.096062Z","shell.execute_reply":"2023-02-15T23:57:27.180598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.columns","metadata":{"execution":{"iopub.status.busy":"2023-02-15T23:57:32.848917Z","iopub.execute_input":"2023-02-15T23:57:32.849220Z","iopub.status.idle":"2023-02-15T23:57:32.855319Z","shell.execute_reply.started":"2023-02-15T23:57:32.849193Z","shell.execute_reply":"2023-02-15T23:57:32.854008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To build hypotheses, it is necessary to clearly understand the task: in our case, the goal is to predict the price of a residential building. At the same time, the data contains 38 columns (characteristics), among which there are non-informative features (such as id) and the target variable (SalePrice). Let's start with the target variable.","metadata":{}},{"cell_type":"code","source":"df_train['SalePrice'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-02-15T23:57:55.539262Z","iopub.execute_input":"2023-02-15T23:57:55.539773Z","iopub.status.idle":"2023-02-15T23:57:55.549595Z","shell.execute_reply.started":"2023-02-15T23:57:55.539736Z","shell.execute_reply":"2023-02-15T23:57:55.548903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(df_train['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2023-02-15T23:58:05.708310Z","iopub.execute_input":"2023-02-15T23:58:05.708658Z","iopub.status.idle":"2023-02-15T23:58:05.960684Z","shell.execute_reply.started":"2023-02-15T23:58:05.708628Z","shell.execute_reply":"2023-02-15T23:58:05.959805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What conclusions can be drawn?\nFirstly, it seems that the data looks correct (the price is greater than 0, there are no obvious outliers) and there is a clear trend towards a biased normal distribution with an expected value of ~18000 and std ~ 79000 (quite a large spread).\n\nFinal step:\nwrite the target variable into a separate variable, removing it from the features","metadata":{}},{"cell_type":"code","source":"y_train = df_train.SalePrice.values\nx_train = df_train.drop('SalePrice', 1)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:34:21.456250Z","iopub.execute_input":"2023-02-19T21:34:21.456676Z","iopub.status.idle":"2023-02-19T21:34:21.466609Z","shell.execute_reply.started":"2023-02-19T21:34:21.456639Z","shell.execute_reply":"2023-02-19T21:34:21.465756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building hypotheses. signs","metadata":{}},{"cell_type":"code","source":"data = pd.concat([df_train['SalePrice'], df_train['OverallQual']], axis=1)\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='OverallQual', y=\"SalePrice\", data=data)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:00:26.311393Z","iopub.execute_input":"2023-02-16T00:00:26.311881Z","iopub.status.idle":"2023-02-16T00:00:26.528161Z","shell.execute_reply.started":"2023-02-16T00:00:26.311854Z","shell.execute_reply":"2023-02-16T00:00:26.527070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([df_train['SalePrice'], df_train['GrLivArea']], axis=1)\ndata.plot.scatter(x='GrLivArea', y='SalePrice')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:34:45.313259Z","iopub.execute_input":"2023-02-19T21:34:45.313906Z","iopub.status.idle":"2023-02-19T21:34:45.546810Z","shell.execute_reply.started":"2023-02-19T21:34:45.313853Z","shell.execute_reply":"2023-02-19T21:34:45.546020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([df_train['SalePrice'], df_train['TotalBsmtSF']], axis=1)\ndata.plot.scatter(x='TotalBsmtSF', y='SalePrice')","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:00:34.071684Z","iopub.execute_input":"2023-02-16T00:00:34.071995Z","iopub.status.idle":"2023-02-16T00:00:34.313503Z","shell.execute_reply.started":"2023-02-16T00:00:34.071969Z","shell.execute_reply":"2023-02-16T00:00:34.312482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For numerical variables (TotalBsmtSF, GrLivArea) we observe a linear trend\n\nConsider a delayed feature - Neighborhood","metadata":{}},{"cell_type":"code","source":"data = pd.concat([df_train['SalePrice'], df_train['Neighborhood']], axis=1)\nplt.figure(figsize=(20, 6))\nsns.boxplot(x='Neighborhood', y=\"SalePrice\", data=data)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:00:44.939893Z","iopub.execute_input":"2023-02-16T00:00:44.940224Z","iopub.status.idle":"2023-02-16T00:00:45.359029Z","shell.execute_reply.started":"2023-02-16T00:00:44.940192Z","shell.execute_reply":"2023-02-16T00:00:45.357944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no obvious trend, but at the same time, one can single out, for example, expensive areas (albeit with a very wide spread) and the local \"Ghetto\" - BrDale","metadata":{}},{"cell_type":"markdown","source":"To make sure we don't miss anything - build our own heatmap","metadata":{}},{"cell_type":"code","source":"#correlation matrix\ncorrmat = df_train.corr()\nplt.figure(figsize=(12, 12))\nsns.heatmap(corrmat, vmax=.8, square=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:00:53.497738Z","iopub.execute_input":"2023-02-16T00:00:53.498116Z","iopub.status.idle":"2023-02-16T00:00:54.048897Z","shell.execute_reply.started":"2023-02-16T00:00:53.498084Z","shell.execute_reply":"2023-02-16T00:00:54.047989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see confirmation of the importance of the OverallQual feature. We also see many interesting connections here - for example, we can conclude that garages are built together with the house =) (GarageYearBlt - YearBllt); but LotArea surprisingly does not affect the price much.\n\nYou can analyze the data for a long time and find interesting dependencies, but let's get back to iterative development and move on to the next step.","metadata":{}},{"cell_type":"markdown","source":"## Data preparation: filling in the gaps","metadata":{}},{"cell_type":"markdown","source":"There are several classic approaches - drop rows with such data, fill with an average, fill with something logical (depending on the specifics of the data), build, for example, RF and fill in the gaps iteratively. Let's start by looking at the missing values.","metadata":{}},{"cell_type":"code","source":"total = df_train.isnull().sum().sort_values(ascending=False)\npercent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:35:13.142276Z","iopub.execute_input":"2023-02-19T21:35:13.142830Z","iopub.status.idle":"2023-02-19T21:35:13.189863Z","shell.execute_reply.started":"2023-02-19T21:35:13.142782Z","shell.execute_reply":"2023-02-19T21:35:13.189044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's analyze: the first 6 candidates have a large percentage of missing values (more than 17) - since these features did not have a strong correlation in the previous analysis - we will replace it with the most frequent value. For the rest, we will remove the missing values","metadata":{}},{"cell_type":"code","source":"x_train = x_train.drop((missing_data[missing_data['Total'] > 81]).index,1)\nx_train = x_train.apply(lambda x:x.fillna(x.value_counts().index[0]))\nx_train.isnull().sum().max()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:35:19.467980Z","iopub.execute_input":"2023-02-19T21:35:19.468527Z","iopub.status.idle":"2023-02-19T21:35:19.563254Z","shell.execute_reply.started":"2023-02-19T21:35:19.468465Z","shell.execute_reply":"2023-02-19T21:35:19.562124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:04:21.090167Z","iopub.execute_input":"2023-02-16T00:04:21.090466Z","iopub.status.idle":"2023-02-16T00:04:21.095815Z","shell.execute_reply.started":"2023-02-16T00:04:21.090440Z","shell.execute_reply":"2023-02-16T00:04:21.094972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's deal with the missing values in the test - you can't drop rows","metadata":{}},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:04:30.465013Z","iopub.execute_input":"2023-02-16T00:04:30.465567Z","iopub.status.idle":"2023-02-16T00:04:30.486228Z","shell.execute_reply.started":"2023-02-16T00:04:30.465532Z","shell.execute_reply":"2023-02-16T00:04:30.485261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = df_test.drop((missing_data[missing_data['Total'] > 81]).index,1)\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:35:32.523536Z","iopub.execute_input":"2023-02-19T21:35:32.524149Z","iopub.status.idle":"2023-02-19T21:35:32.560291Z","shell.execute_reply.started":"2023-02-19T21:35:32.524110Z","shell.execute_reply":"2023-02-19T21:35:32.559596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = df_test.apply(lambda x:x.fillna(x.value_counts().index[0]))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:35:41.295958Z","iopub.execute_input":"2023-02-19T21:35:41.296301Z","iopub.status.idle":"2023-02-19T21:35:41.378271Z","shell.execute_reply.started":"2023-02-19T21:35:41.296271Z","shell.execute_reply":"2023-02-19T21:35:41.377516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-17T18:26:28.494023Z","iopub.execute_input":"2023-02-17T18:26:28.494646Z","iopub.status.idle":"2023-02-17T18:26:28.501362Z","shell.execute_reply.started":"2023-02-17T18:26:28.494606Z","shell.execute_reply":"2023-02-17T18:26:28.500054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation. Normalization and cleaning","metadata":{}},{"cell_type":"markdown","source":"Let's remove the identifiers, since they are unique and non-ifnormative. Let's do the same for the test","metadata":{}},{"cell_type":"code","source":"x_train.drop(\"Id\", axis = 1, inplace = True)\ndf_test.drop(\"Id\", axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:35:50.906887Z","iopub.execute_input":"2023-02-19T21:35:50.907245Z","iopub.status.idle":"2023-02-19T21:35:50.916215Z","shell.execute_reply.started":"2023-02-19T21:35:50.907215Z","shell.execute_reply":"2023-02-19T21:35:50.915232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:05:14.662751Z","iopub.execute_input":"2023-02-16T00:05:14.663114Z","iopub.status.idle":"2023-02-16T00:05:14.670028Z","shell.execute_reply.started":"2023-02-16T00:05:14.663083Z","shell.execute_reply":"2023-02-16T00:05:14.668459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:05:17.784952Z","iopub.execute_input":"2023-02-16T00:05:17.785258Z","iopub.status.idle":"2023-02-16T00:05:17.791496Z","shell.execute_reply.started":"2023-02-16T00:05:17.785231Z","shell.execute_reply":"2023-02-16T00:05:17.790387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoding of categorical variables - translate into numerical values. same for test","metadata":{}},{"cell_type":"code","source":"x_train.select_dtypes(include='object').columns","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:05:24.776763Z","iopub.execute_input":"2023-02-16T00:05:24.777049Z","iopub.status.idle":"2023-02-16T00:05:24.786470Z","shell.execute_reply.started":"2023-02-16T00:05:24.777024Z","shell.execute_reply":"2023-02-16T00:05:24.785091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncols = x_train.select_dtypes(include='object').columns\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(x_train[c].values)) \n    x_train[c] = lbl.transform(list(x_train[c].values))\n    df_test[c] = lbl.transform(list(df_test[c].values))\n\nprint('Shape all_data: {}'.format(x_train.shape))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:36:03.778545Z","iopub.execute_input":"2023-02-19T21:36:03.778967Z","iopub.status.idle":"2023-02-19T21:36:03.874960Z","shell.execute_reply.started":"2023-02-19T21:36:03.778922Z","shell.execute_reply":"2023-02-19T21:36:03.873800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's clean up the data a little more from outliers: ","metadata":{}},{"cell_type":"code","source":"indexes = x_train[(df_train['GrLivArea']>4000) & (df_train['SalePrice']<300000)].index \n\nx_train = x_train.drop(indexes)\ny_train = np.delete(y_train, indexes)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:36:14.191368Z","iopub.execute_input":"2023-02-19T21:36:14.191991Z","iopub.status.idle":"2023-02-19T21:36:14.201697Z","shell.execute_reply.started":"2023-02-19T21:36:14.191954Z","shell.execute_reply":"2023-02-19T21:36:14.200778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" x_train.shape,y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:07:21.850787Z","iopub.execute_input":"2023-02-16T00:07:21.851128Z","iopub.status.idle":"2023-02-16T00:07:21.855884Z","shell.execute_reply.started":"2023-02-16T00:07:21.851094Z","shell.execute_reply":"2023-02-16T00:07:21.855214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The process of data preparation can be continued indefinitely, generating new features, filling in gaps in different ways, etc. But let's go further, build the first model and see what we already have","metadata":{}},{"cell_type":"markdown","source":"## Building the model","metadata":{}},{"cell_type":"code","source":"# Test split the data \nfrom sklearn.model_selection import train_test_split\nx_train1,x_valid,y_train1,y_valid = train_test_split(x_train,y_train,test_size = 0.1,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:36:56.752676Z","iopub.execute_input":"2023-02-19T21:36:56.753037Z","iopub.status.idle":"2023-02-19T21:36:56.807733Z","shell.execute_reply.started":"2023-02-19T21:36:56.753010Z","shell.execute_reply":"2023-02-19T21:36:56.806788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:37:13.609977Z","iopub.execute_input":"2023-02-19T21:37:13.610382Z","iopub.status.idle":"2023-02-19T21:37:14.745927Z","shell.execute_reply.started":"2023-02-19T21:37:13.610313Z","shell.execute_reply":"2023-02-19T21:37:14.745110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xgb = xgb.XGBRegressor(n_estimators=2200)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:39:08.447713Z","iopub.execute_input":"2023-02-19T21:39:08.448113Z","iopub.status.idle":"2023-02-19T21:39:08.452619Z","shell.execute_reply.started":"2023-02-19T21:39:08.448082Z","shell.execute_reply":"2023-02-19T21:39:08.451803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 5\n\ndef rmse(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse = np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)\n\ndef rmse(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:39:13.813815Z","iopub.execute_input":"2023-02-19T21:39:13.814205Z","iopub.status.idle":"2023-02-19T21:39:13.821517Z","shell.execute_reply.started":"2023-02-19T21:39:13.814168Z","shell.execute_reply":"2023-02-19T21:39:13.820524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGB Method**","metadata":{}},{"cell_type":"code","source":"model_xgb.fit(x_train1, y_train1)\nxgb_train_pred = model_xgb.predict(x_valid)\nxgb_pred = model_xgb.predict(df_test)\nprint(rmse(y_valid, xgb_train_pred)) ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:39:22.762697Z","iopub.execute_input":"2023-02-19T21:39:22.763369Z","iopub.status.idle":"2023-02-19T21:39:28.310484Z","shell.execute_reply.started":"2023-02-19T21:39:22.763330Z","shell.execute_reply":"2023-02-19T21:39:28.309516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\nmean_squared_log_error(y_valid, xgb_train_pred)  ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:39:36.470982Z","iopub.execute_input":"2023-02-19T21:39:36.471309Z","iopub.status.idle":"2023-02-19T21:39:36.477312Z","shell.execute_reply.started":"2023-02-19T21:39:36.471281Z","shell.execute_reply":"2023-02-19T21:39:36.476642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After a few iterations, a still simple regressor with a lot of estimators gave a good result!\nDoesn't look like a top 1 score yet.","metadata":{}},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = ids\nsub['SalePrice'] = xgb_pred\nsub.to_csv('submission.csv',index=False) ","metadata":{"execution":{"iopub.status.busy":"2023-02-16T00:08:57.943683Z","iopub.execute_input":"2023-02-16T00:08:57.944031Z","iopub.status.idle":"2023-02-16T00:08:58.217657Z","shell.execute_reply.started":"2023-02-16T00:08:57.943993Z","shell.execute_reply":"2023-02-16T00:08:58.216487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's tune the model, let's try to rise a little","metadata":{}},{"cell_type":"code","source":"model_xgb = xgb.XGBRegressor(reg_lambda=0.8571, n_estimators=2200, nthread = -1)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:41:27.241067Z","iopub.execute_input":"2023-02-19T21:41:27.241493Z","iopub.status.idle":"2023-02-19T21:41:27.247333Z","shell.execute_reply.started":"2023-02-19T21:41:27.241441Z","shell.execute_reply":"2023-02-19T21:41:27.246113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_xgb.fit(x_train1, y_train1)\nxgb_train_pred1 = model_xgb.predict(x_valid)\nxgb_pred = model_xgb.predict(df_test)\nprint(rmse(y_valid, xgb_train_pred1))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:41:42.776670Z","iopub.execute_input":"2023-02-19T21:41:42.777321Z","iopub.status.idle":"2023-02-19T21:41:56.924261Z","shell.execute_reply.started":"2023-02-19T21:41:42.777280Z","shell.execute_reply":"2023-02-19T21:41:56.923247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_log_error(y_valid, xgb_train_pred)  ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:42:06.766535Z","iopub.execute_input":"2023-02-19T21:42:06.767186Z","iopub.status.idle":"2023-02-19T21:42:06.774917Z","shell.execute_reply.started":"2023-02-19T21:42:06.767134Z","shell.execute_reply":"2023-02-19T21:42:06.773990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = ids\nsub['SalePrice'] = xgb_pred\nsub.to_csv('submission.csv',index=False) ","metadata":{"execution":{"iopub.status.busy":"2023-02-07T14:01:12.009247Z","iopub.execute_input":"2023-02-07T14:01:12.009699Z","iopub.status.idle":"2023-02-07T14:01:12.024420Z","shell.execute_reply.started":"2023-02-07T14:01:12.009662Z","shell.execute_reply":"2023-02-07T14:01:12.023480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stacked and Ensemble Models","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import ElasticNet, Lasso\nimport lightgbm as lgb\n\nclass StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:42:26.223441Z","iopub.execute_input":"2023-02-19T21:42:26.224089Z","iopub.status.idle":"2023-02-19T21:42:26.275283Z","shell.execute_reply.started":"2023-02-19T21:42:26.224033Z","shell.execute_reply":"2023-02-19T21:42:26.274227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's assemble a model consisting of a set of basic classifiers of different types","metadata":{}},{"cell_type":"code","source":"KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n\nGBoost = GradientBoostingRegressor(n_estimators=3000, random_state =42)\n\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005,random_state=42))\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=42))\n\nstacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n                                                 meta_model = lasso)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:42:34.017573Z","iopub.execute_input":"2023-02-19T21:42:34.017934Z","iopub.status.idle":"2023-02-19T21:42:34.024931Z","shell.execute_reply.started":"2023-02-19T21:42:34.017903Z","shell.execute_reply":"2023-02-19T21:42:34.023781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nmodel_xgb = xgb.XGBRegressor(n_estimators=2200, nthread = -1)\nmodel_xgb.fit(x_train1, y_train1)\n\nmodel_lgb = lgb.LGBMRegressor(objective='regression',n_estimators=720)\nmodel_lgb.fit(x_train1, y_train1) \n\nstacked_pred=stacked_averaged_models.fit(x_train1.values, y_train1)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:42:51.301309Z","iopub.execute_input":"2023-02-19T21:42:51.301667Z","iopub.status.idle":"2023-02-19T21:44:32.693391Z","shell.execute_reply.started":"2023-02-19T21:42:51.301637Z","shell.execute_reply":"2023-02-19T21:44:32.692589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_pred = model_lgb.predict(x_valid)\nxgb_pred = model_xgb.predict(x_valid)\nstacked_pred = stacked_averaged_models.predict(x_valid.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:45:09.089760Z","iopub.execute_input":"2023-02-19T21:45:09.090106Z","iopub.status.idle":"2023-02-19T21:45:09.189205Z","shell.execute_reply.started":"2023-02-19T21:45:09.090077Z","shell.execute_reply":"2023-02-19T21:45:09.188376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rmse(y_valid, stacked_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:45:22.647192Z","iopub.execute_input":"2023-02-19T21:45:22.647585Z","iopub.status.idle":"2023-02-19T21:45:22.653840Z","shell.execute_reply.started":"2023-02-19T21:45:22.647542Z","shell.execute_reply":"2023-02-19T21:45:22.652757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\nmean_squared_log_error(y_valid, stacked_pred)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:45:29.535052Z","iopub.execute_input":"2023-02-19T21:45:29.535426Z","iopub.status.idle":"2023-02-19T21:45:29.541894Z","shell.execute_reply.started":"2023-02-19T21:45:29.535396Z","shell.execute_reply":"2023-02-19T21:45:29.541126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_pred = model_lgb.predict(df_test)\nxgb_pred = model_xgb.predict(df_test)\nstacked_pred = stacked_averaged_models.predict(df_test.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T18:51:30.972925Z","iopub.execute_input":"2023-02-17T18:51:30.973310Z","iopub.status.idle":"2023-02-17T18:51:31.741059Z","shell.execute_reply.started":"2023-02-17T18:51:30.973276Z","shell.execute_reply":"2023-02-17T18:51:31.739928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = ids\nsub['SalePrice'] = xgb_pred\nsub.to_csv('submission.csv',index=False) ","metadata":{"execution":{"iopub.status.busy":"2023-02-07T14:14:46.448896Z","iopub.execute_input":"2023-02-07T14:14:46.449356Z","iopub.status.idle":"2023-02-07T14:14:46.463710Z","shell.execute_reply.started":"2023-02-07T14:14:46.449320Z","shell.execute_reply":"2023-02-07T14:14:46.462008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:45:54.188897Z","iopub.execute_input":"2023-02-19T21:45:54.189267Z","iopub.status.idle":"2023-02-19T21:45:54.194044Z","shell.execute_reply.started":"2023-02-19T21:45:54.189235Z","shell.execute_reply":"2023-02-19T21:45:54.193230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rmse(y_valid, ensemble))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:46:00.845019Z","iopub.execute_input":"2023-02-19T21:46:00.845456Z","iopub.status.idle":"2023-02-19T21:46:00.851815Z","shell.execute_reply.started":"2023-02-19T21:46:00.845413Z","shell.execute_reply":"2023-02-19T21:46:00.850622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_log_error(y_valid, ensemble) ","metadata":{"execution":{"iopub.status.busy":"2023-02-19T21:46:08.194415Z","iopub.execute_input":"2023-02-19T21:46:08.194789Z","iopub.status.idle":"2023-02-19T21:46:08.200460Z","shell.execute_reply.started":"2023-02-19T21:46:08.194757Z","shell.execute_reply":"2023-02-19T21:46:08.199782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_pred = model_lgb.predict(df_test)\nxgb_pred = model_xgb.predict(df_test)\nstacked_pred = stacked_averaged_models.predict(df_test.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:17:52.611840Z","iopub.execute_input":"2023-02-01T15:17:52.612217Z","iopub.status.idle":"2023-02-01T15:17:53.360433Z","shell.execute_reply.started":"2023-02-01T15:17:52.612185Z","shell.execute_reply":"2023-02-01T15:17:53.359237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:18:11.641076Z","iopub.execute_input":"2023-02-01T15:18:11.641883Z","iopub.status.idle":"2023-02-01T15:18:11.648077Z","shell.execute_reply.started":"2023-02-01T15:18:11.641842Z","shell.execute_reply":"2023-02-01T15:18:11.646459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame() \nsub['Id'] = ids\nsub['SalePrice'] = xgb_pred\nsub.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}